# Planning Poker Deployment Guide

This guide covers deploying Planning Poker with the MoosicBox Load Balancer to Kubernetes.

## Architecture

```
Internet → Cloudflare DNS → DigitalOcean Node IP:80/443
                                    ↓
                          MoosicBox Load Balancer Pod
                          (hostPort binding + SSL termination + routing + ACME challenges)
                                    ↓
                    ┌─────────────────┴─────────────────┐
                    ↓                                   ↓
        Planning Poker Service                 ACME Solver Service
            (ClusterIP)                           (ClusterIP)
                    ↓                                   ↓
        Planning Poker Pod(s)                   ACME Solver Pod
                                                (for Let's Encrypt)

        cert-manager (separate namespace)
        ↓
        Let's Encrypt Certificate Management
```

**Key Cost Savings:**

- ✅ **No DigitalOcean LoadBalancer** (~$12/month saved)
- ✅ **Direct node access** via hostPort binding
- ✅ **Standard ports 80/443** for HTTP/HTTPS

## Prerequisites

1. **Tools Required:**

   - `clippier` - For generating Dockerfiles from GitHub repos
   - `docker` - For building container images
   - `terraform` - For infrastructure deployment
   - `kubectl` - For Kubernetes management
   - `doctl` - For DigitalOcean CLI access

2. **Environment Variables:**

   ```bash
   export DIGITALOCEAN_TOKEN="your-do-token"
   export CLOUDFLARE_API_TOKEN="your-cf-token"
   export DATABASE_URL="postgresql://user:pass@host:port/db"
   ```

3. **Authentication:**

   ```bash
   # Login to DigitalOcean Container Registry
   doctl registry login

   # Verify Kubernetes access
   doctl kubernetes cluster kubeconfig save planning-poker-test
   ```

## Quick Deployment

### Build and Deploy Everything

```bash
# Deploy to test environment
./terraform/scripts/build-and-deploy.sh test latest

# Deploy to production
./terraform/scripts/build-and-deploy.sh prod v1.0.0
```

This script will:

1. Generate Dockerfiles using clippier
2. Build both Planning Poker and MoosicBox Load Balancer containers
3. Push images to DigitalOcean Container Registry
4. Deploy to Kubernetes using Terraform
5. Wait for services to be ready
6. Show deployment status and monitoring commands

## Manual Deployment Steps

### 1. Build Containers

```bash
# Set environment variables
export ENVIRONMENT="test"
export IMAGE_TAG="latest"
export PUSH_IMAGE="true"

# Build and push both containers
./terraform/scripts/build-container.sh
```

### 2. Deploy Infrastructure

```bash
# Navigate to terraform directory
cd terraform/environments

# Select workspace
terraform workspace select test  # or prod

# Deploy
terraform apply -var="image_tag=latest"
```

### 3. Monitor Deployment

```bash
# Check pod status
kubectl get pods -n planning-poker-test

# Check services
kubectl get services -n planning-poker-test

# Check certificates
kubectl get certificates -n planning-poker-test

# View logs
kubectl logs -f deployment/planning-poker -n planning-poker-test
kubectl logs -f deployment/moosicbox-lb -n planning-poker-test
```

## Container Images

### Planning Poker App

- **Generated by:** `clippier` from local workspace
- **Dockerfile:** `packages/app/PlanningPoker.Dockerfile`
- **Registry:** `registry.digitalocean.com/planning-poker/planning-poker:TAG`

### MoosicBox Load Balancer

- **Generated by:** `clippier https://github.com/MoosicBox/MoosicBox moosicbox_load_balancer`
- **Dockerfile:** `MoosicBoxLoadBalancer.Dockerfile` (temporary)
- **Registry:** `registry.digitalocean.com/planning-poker/moosicbox-lb:TAG`

## Configuration

### MoosicBox Load Balancer Environment Variables

```bash
CLUSTERS="test.planning-poker.hyperchad.dev:planning-poker-service.planning-poker-test.svc.cluster.local:80"
PORT="80"             # Standard HTTP port (bound to hostPort)
SSL_PORT="443"        # Standard HTTPS port (bound to hostPort)
SSL_CRT_PATH="/etc/ssl/certs/tls.crt"
SSL_KEY_PATH="/etc/ssl/private/tls.key"
```

### NodePort Configuration

- **Service Type:** `NodePort` (not LoadBalancer)
- **Host Port Binding:** Pods bind directly to node ports 80/443 via `hostPort`
- **DNS Target:** Points directly to Kubernetes node external IP
- **Cost:** $0 (no LoadBalancer charges)

### SSL Certificates

- **Managed by:** cert-manager with Let's Encrypt
- **Issuer:** `letsencrypt-prod` (configurable via `cert_manager_issuer` variable)
- **Email:** Configurable via `letsencrypt_email` variable (default: BradenSteffaniak@gmail.com)
- **Secret:** `planning-poker-tls`
- **Domains:** Automatically configured based on environment
- **Challenge Method:** HTTP-01 via MoosicBox load balancer and ACME solver service
- **Renewal:** Automatic (15 days before expiry)

## Environments

### Test Environment

- **URL:** https://test.planning-poker.hyperchad.dev
- **Namespace:** `planning-poker-test`
- **Workspace:** `test`

### Production Environment

- **URL:** https://planning-poker.hyperchad.dev
- **Namespace:** `planning-poker-prod`
- **Workspace:** `prod`

## Troubleshooting

### NodePort and Host Binding Issues

```bash
# Check service status (should be NodePort, not LoadBalancer)
kubectl get service moosicbox-lb-service -n planning-poker-test

# Check if pod is bound to host ports
kubectl get pods -n planning-poker-test -o wide
kubectl describe pod -l app=moosicbox-lb -n planning-poker-test

# Check node external IPs
kubectl get nodes -o wide

# Test direct node access
curl -I http://NODE_EXTERNAL_IP/
curl -I https://NODE_EXTERNAL_IP/

# Check if ports 80/443 are bound on the node
# (SSH to node if needed)
# netstat -tlnp | grep -E ':80|:443'
```

### Certificate Issues

```bash
# Check certificate status
kubectl describe certificate planning-poker-tls -n planning-poker-test
kubectl get certificate planning-poker-tls -n planning-poker-test -o wide

# Check certificate secret
kubectl describe secret planning-poker-tls -n planning-poker-test

# Check certificate request status
kubectl get certificaterequests -n planning-poker-test
kubectl describe certificaterequests -n planning-poker-test

# Check cert-manager logs
kubectl logs -n cert-manager deployment/cert-manager
kubectl logs -n cert-manager deployment/cert-manager-webhook
kubectl logs -n cert-manager deployment/cert-manager-cainjector

# Check ClusterIssuer status
kubectl describe clusterissuer letsencrypt-prod
kubectl get clusterissuer letsencrypt-prod -o wide

# Check ACME challenge status (if any)
kubectl get challenges -n planning-poker-test
kubectl describe challenges -n planning-poker-test

# Check ACME solver service
kubectl get pods -l app=acme-solver -n planning-poker-test
kubectl logs -l app=acme-solver -n planning-poker-test

# Force certificate renewal (if needed)
kubectl delete certificate planning-poker-tls -n planning-poker-test
# Then re-run terraform apply to recreate it
```

### DNS Issues

```bash
# Check DNS resolution
dig test.planning-poker.hyperchad.dev

# Check Cloudflare DNS records
# (Use Cloudflare dashboard or API)
```

### Container Build Issues

```bash
# Check if clippier is installed
which clippier

# Manually generate Dockerfile
clippier https://github.com/MoosicBox/MoosicBox moosicbox_load_balancer --output MoosicBoxLoadBalancer.Dockerfile

# Check Docker build context
docker build -f MoosicBoxLoadBalancer.Dockerfile -t test .
```

## Monitoring

### Health Checks

- **Planning Poker:** HTTP GET `/health` on port 8080
- **MoosicBox LB:** TCP check on port 80 (HTTP) and 443 (HTTPS)

### Logs

```bash
# Application logs
kubectl logs -f deployment/planning-poker -n planning-poker-test

# Load balancer logs
kubectl logs -f deployment/moosicbox-lb -n planning-poker-test

# All pods in namespace
kubectl logs -f -l app=planning-poker -n planning-poker-test
```

### Metrics

```bash
# Resource usage
kubectl top pods -n planning-poker-test

# Service endpoints
kubectl get endpoints -n planning-poker-test
```

## Scaling

### Manual Scaling

```bash
# Scale Planning Poker pods
kubectl scale deployment planning-poker --replicas=3 -n planning-poker-test

# Note: MoosicBox Load Balancer should remain at 1 replica
```

### Auto-scaling

Configure HPA in Terraform variables:

```hcl
enable_hpa = true
hpa_min_replicas = 1
hpa_max_replicas = 5
hpa_cpu_target = 70
```

## Security

### Network Policies

- Planning Poker pods only accept traffic from MoosicBox Load Balancer
- MoosicBox Load Balancer accepts traffic from LoadBalancer service

### SSL/TLS

- All traffic encrypted with Let's Encrypt certificates
- Automatic certificate renewal via cert-manager
- HTTPS redirect enforced by MoosicBox Load Balancer

### Container Security

- Non-root containers
- Read-only root filesystems where possible
- Resource limits enforced
- Registry credentials stored as Kubernetes secrets
